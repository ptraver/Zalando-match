{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38597ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d396e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0655bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "matches_training_df = pd.read_parquet('matches_training.parquet')\n",
    "offers_training_df = pd.read_parquet('offers_training.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10a9e78",
   "metadata": {},
   "source": [
    "# TRAIN, VALIDATION, TEST sets preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49c15e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic text preprocessing function to get lowercase and adjust all German nuances such as 'ü' and 'ß'\n",
    "\n",
    "import unidecode\n",
    "\n",
    "# Takes a string. Returns that string lowercased with accents removed.\n",
    "def transform_txt(txt):\n",
    "    txt = unidecode.unidecode(txt)\n",
    "    txt = txt.lower()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56790797",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'offers_training_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7d1bbc291c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransform_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moffers_training_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'brand'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffers_training_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'brand'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtransform_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'offers_training_df' is not defined"
     ]
    }
   ],
   "source": [
    "#preprocess brand so that it's just its first word\n",
    "#this holds for ~97% of training matches , but still plenty of room for improvements\n",
    "\n",
    "import re\n",
    "\n",
    "def process_brand(txt):\n",
    "    txt = re.sub('[^a-zA-Z ]+', '', txt)\n",
    "    return transform_txt(txt).split()[0]\n",
    "\n",
    "offers_training_df['brand'] = offers_training_df['brand'].apply(lambda x: transform_txt(x).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "daec7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess price\n",
    "\n",
    "offers_training_df['price'] = offers_training_df['price'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56d50069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40904, 10)\n",
      "(61980, 10)\n",
      "(40876, 10)\n",
      "(61978, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Split zalando and aboutyou offers into their own dataframes\n",
    "\n",
    "zal_offers = offers_training_df[offers_training_df['shop']=='zalando']\n",
    "aboutyou_offers = offers_training_df[offers_training_df['shop']=='aboutyou']\n",
    "\n",
    "print(zal_offers.shape)\n",
    "print(aboutyou_offers.shape)\n",
    "\n",
    "zal_offers.dropna(inplace=True)\n",
    "aboutyou_offers.dropna(inplace=True)\n",
    "\n",
    "print(zal_offers.shape)\n",
    "print(aboutyou_offers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa8deb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess description fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1fd232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a string of zalando description (messy key-values delimited by '$') and returns a clean list of words\n",
    "\n",
    "def process_zal_descr(txt):\n",
    "    bag = []\n",
    "    \n",
    "    for chunk in txt.split(' $ '):\n",
    "        for word in chunk.split()[1:]:\n",
    "            processed_word = transform_txt(word)\n",
    "            if len(processed_word) >= 3 and processed_word.isalpha() and processed_word not in bag and processed_word not in ['bei', 'mit']:\n",
    "                bag.append(processed_word)\n",
    "    \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "829cbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a string of aboutyou description (messy json and some html) and returns a clean list of words from the json part\n",
    "\n",
    "import re\n",
    "\n",
    "def process_aboutyou_json(txt):\n",
    "    \n",
    "    bag = []\n",
    "    \n",
    "    for json in re.findall(r\"\\[\\\"(.+?)\\\"\\]\", txt):\n",
    "        for chunk in json.split():\n",
    "            for word in re.findall(r\"([\\w]+)\", chunk):\n",
    "                processed_word = transform_txt(word)\n",
    "                if len(processed_word) >= 3 and processed_word.isalpha() and processed_word not in bag and processed_word not in ['bei', 'mit']:\n",
    "                    bag.append(processed_word)\n",
    "    \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46cbb06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a string of aboutyou description (messy json and some html) and returns a clean list of words from the html part\n",
    "\n",
    "def process_aboutyou_html(txt):\n",
    "    bag = []\n",
    "    \n",
    "    for chunk in re.findall(r\"<td>(.+?)</td>\", txt):\n",
    "        for word in re.findall(r\"([\\w]+)\", chunk):\n",
    "            processed_word = transform_txt(word)\n",
    "            if len(processed_word) >= 3 and processed_word.isalpha() and processed_word not in bag and processed_word not in ['bei', 'mit']:\n",
    "                bag.append(processed_word)\n",
    "    \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "645c07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes an aboutyou description and returns the combined outputs of process_aboutyou_json() and process_aboutyou_html()\n",
    "\n",
    "def process_aboutyou_descr(txt):\n",
    "    return process_aboutyou_json(txt) + process_aboutyou_html(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d1cc9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Call functions to preprocess descriptions\n",
    "\n",
    "zal_offers['description'] = zal_offers['description'].apply(process_zal_descr)\n",
    "aboutyou_offers['description'] = aboutyou_offers['description'].apply(process_aboutyou_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60c6eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess color fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cdda557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a string of zalando color and returns a preprocessed string\n",
    "\n",
    "import re\n",
    "\n",
    "def process_zal_color(txt):\n",
    "\n",
    "    #normalise\n",
    "    txt = transform_txt(txt)\n",
    "\n",
    "    #replace non-alphanumeric with space\n",
    "    txt = re.sub('[^a-zA-Z]+', ' ', txt)\n",
    "\n",
    "    #remove dunkel, hell\n",
    "    txt = txt.replace(\"dunkel\", \"\")\n",
    "    txt = txt.replace(\"hell\", \"\")\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c70454a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a string of aboutyou color and returns a preprocessed version\n",
    "\n",
    "def process_aboutyou_color(txt):\n",
    "    \n",
    "    #normalise\n",
    "    txt = transform_txt(txt)\n",
    "\n",
    "    #remove dunkel, hell\n",
    "    txt = txt.replace(\"dunkel\", \"\")\n",
    "    txt = txt.replace(\"hell\", \"\")\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ef13bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Call color preprocessing functions\n",
    "\n",
    "zal_offers['color'] = zal_offers['color'].apply(process_zal_color)\n",
    "aboutyou_offers['color'] = aboutyou_offers['color'].apply(process_aboutyou_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8357f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a row with columns 'left_color' and 'right_color', returns True if any of left_color' in 'right_color'\n",
    "\n",
    "def compare_color(x):\n",
    "\n",
    "    for word in x['left_color'].split():\n",
    "        if word in x['right_color']:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5cdd07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess title fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "272744f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a string of zalando title and returns a preprocessed version\n",
    "\n",
    "def process_zal_title(txt):\n",
    "    #normalise\n",
    "    return transform_txt(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d97d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a string of aboutyou title and returns a preprocessed version\n",
    "def process_aboutyou_title(txt):\n",
    "    \n",
    "    #normalise\n",
    "    txt = transform_txt(txt)\n",
    "\n",
    "    #remove apostrophes\n",
    "    txt = txt.replace(\"'\", \"\")\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "461dd6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Call functions to preprocess title\n",
    "\n",
    "zal_offers['title'] = zal_offers['title'].apply(process_zal_title)\n",
    "aboutyou_offers['title'] = aboutyou_offers['title'].apply(process_aboutyou_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98786680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a row with two 'left_title' and 'right_title' columns\n",
    "# Returns True if any word is contained anywhere in the other\n",
    "\n",
    "def title_words_in_common(x):\n",
    "    for word in x['left_title'].split():\n",
    "        if word in x['right_title']:\n",
    "            return True\n",
    "    for word in x['right_title'].split():\n",
    "        if word in x['left_title']:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0b6cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through an analysis of the expected size of brand cartesian products, combined with the blocking step of comparing\n",
    "# description word counts, it was decided that three different train, validation, test sets would be separated by\n",
    "# brands as below. The brands are listed\n",
    "# below in ascending order of cartesian product\n",
    "\n",
    "brands_1 = ['vaay',\n",
    "'mons',\n",
    "'zarkoperfume',\n",
    "'hot',\n",
    "'davida',\n",
    "'burlington',\n",
    "'bree',\n",
    "'forever',\n",
    "'olivia',\n",
    "'polaroid',\n",
    "'kessler',\n",
    "'jette',\n",
    "'veja',\n",
    "'h.i.s',\n",
    "'wheat',\n",
    "'local',\n",
    "'salamander',\n",
    "'gore',\n",
    "'verbenas',\n",
    "'underprotection',\n",
    "'luhta',\n",
    "'flip*flop',\n",
    "'estelle',\n",
    "'garment',\n",
    "'esme',\n",
    "'fuchs',\n",
    "'rukka',\n",
    "'mother',\n",
    "'kendall',\n",
    "'ag',\n",
    "'didriksons',\n",
    "'farah',\n",
    "'libertine-libertine',\n",
    "'walkiddy',\n",
    "'k-swiss',\n",
    "'saucony',\n",
    "'happy',\n",
    "'dockers',\n",
    "'fritzi',\n",
    "'panama',\n",
    "'envie',\n",
    "'colmar',\n",
    "'huf',\n",
    "'club',\n",
    "'jako',\n",
    "'hust',\n",
    "'herrlicher',\n",
    "'burberry',\n",
    "'call',\n",
    "'denim',\n",
    "'camano',\n",
    "'peak',\n",
    "'jacky',\n",
    "'moves',\n",
    "'primigi',\n",
    "'bruuns',\n",
    "'gestuz',\n",
    "'mennace',\n",
    "'bjorn',\n",
    "'rosemunde',\n",
    "'quiksilver',\n",
    "'swarovski',\n",
    "'free',\n",
    "'bullboxer',\n",
    "'zizzi',\n",
    "'ted',\n",
    "'etam',\n",
    "'rich']\n",
    "\n",
    "brands_2=[\n",
    "'liu',\n",
    "'more',\n",
    "'kaffe',\n",
    "'ellesse',\n",
    "'mamalicious',\n",
    "'lascana']\n",
    "\n",
    "brands_3 = [\n",
    "'selected',\n",
    "'guess',\n",
    "'pieces']\n",
    "\n",
    "too_big=[\n",
    "'vero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b1c28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a row with two 'left_description' and 'right_description' columns (lists).\n",
    "# Returns a count of the number of words they have in common\n",
    "\n",
    "def desc_words_in_common(x):\n",
    "    counter = 0\n",
    "    for word in x['left_description']:\n",
    "        if word in x['right_description']:\n",
    "            counter += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c9eabe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a row with two 'left_price' and 'right_price' columns floats.\n",
    "# Returns the absolute difference in price\n",
    "\n",
    "def price_diff(x):\n",
    "    return abs(x['left_price'] - x['right_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "467a47e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "# A loop to create three train, validation and test sets based on brand groupings defined above\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# only columns of interest for now\n",
    "cols = ['offer_id', 'brand', 'title', 'color', 'description', 'price']\n",
    "\n",
    "# Loop from 1 to 3 since there will three train, validation and test sets\n",
    "for i in range(1, 4):\n",
    "    \n",
    "    # Create train dataframe\n",
    "    globals()[f'train_df_{i}'] = pd.DataFrame()\n",
    "    \n",
    "    brand_group = f'brands_{i}'\n",
    "    for brand in globals()[brand_group]:\n",
    "        # Only take columns of interest\n",
    "        temp_zal = zal_offers[zal_offers['brand'] == brand][cols]\n",
    "        temp_aboutyou = aboutyou_offers[aboutyou_offers['brand'] == brand][cols]\n",
    "        \n",
    "        # Format column names as per deepmatcher requirements\n",
    "        temp_zal = temp_zal.add_prefix('left_')\n",
    "        temp_aboutyou = temp_aboutyou.add_prefix('right_')\n",
    "        \n",
    "        # Create an intra-brand cartesian product\n",
    "        brand_cross = temp_zal.merge(temp_aboutyou, how='cross')\n",
    "        \n",
    "        # Prune from cartesian product pairs with more than 2.5 euro in price difference\n",
    "        if not brand_cross.empty:\n",
    "            brand_cross['price_diff'] = brand_cross.apply(price_diff, axis=1)\n",
    "            brand_cross = brand_cross[brand_cross['price_diff'] <= 2.5]\n",
    "        \n",
    "        if not brand_cross.empty:\n",
    "            brand_cross['color_compare'] = brand_cross.apply(compare_color, axis=1)\n",
    "            brand_cross = brand_cross[brand_cross['color_compare'] == True]\n",
    "            \n",
    "        if not brand_cross.empty:\n",
    "            brand_cross['title_match'] = brand_cross.apply(title_words_in_common, axis=1)\n",
    "            brand_cross = brand_cross[brand_cross['title_match'] == True]\n",
    "        \n",
    "        # Prune from cartesian product pairs with fewer than six words in common in the description\n",
    "        if not brand_cross.empty:\n",
    "            brand_cross['words_in_common'] = brand_cross.apply(desc_words_in_common, axis=1)\n",
    "            brand_cross = brand_cross[brand_cross['words_in_common'] > 5]\n",
    "        \n",
    "        # Append the brand's pruned cartesian product to train_df_{i}\n",
    "        globals()[f'train_df_{i}'] = globals()[f'train_df_{i}'].append(brand_cross, ignore_index=True)\n",
    "        \n",
    "    #  Make the 'label' column in train_df_{i}, indicating ground-truth matches\n",
    "    globals()[f'train_df_{i}'] = globals()[f'train_df_{i}'].merge(matches_training_df\n",
    "                              ,how='left'\n",
    "                              ,left_on=['left_offer_id', 'right_offer_id']\n",
    "                              ,right_on=['zalando', 'aboutyou'])\n",
    "    globals()[f'train_df_{i}'].insert(0, 'label', globals()[f'train_df_{i}']['zalando'].notnull().astype(int))\n",
    "    \n",
    "    # Drop unnecessary columns in train_df_{i}\n",
    "    drop_cols = ['left_offer_id', 'right_offer_id', 'zalando', 'aboutyou', 'brand', 'words_in_common',\n",
    "                'left_description', 'right_description', 'price_diff', 'color_compare', 'title_match']\n",
    "    globals()[f'train_df_{i}'] = globals()[f'train_df_{i}'].drop(drop_cols, 1)\n",
    "    \n",
    "    # Update index name in train_df_{i}\n",
    "    globals()[f'train_df_{i}'].index.names = ['id']\n",
    "    \n",
    "    # Split train_df_{i} into train_df, valid_df and test_df\n",
    "    train_df, holder_df = train_test_split(globals()[f'train_df_{i}'], train_size=0.66, random_state=42, stratify=globals()[f'train_df_{i}']['label'])\n",
    "    valid_df, test_df = train_test_split(holder_df, train_size=0.66, random_state=42, stratify=holder_df['label'])\n",
    "    \n",
    "    # Save train_df, valid_df and test_df as CSVs\n",
    "    cwd = str(os.getcwd())\n",
    "    train_df.to_csv(cwd + f'/train_{i}.csv')\n",
    "    valid_df.to_csv(cwd + f'/validation_{i}.csv')\n",
    "    test_df.to_csv(cwd + f'/test_{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b92b451d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5042, 9)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebaa1136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10300, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a0dc1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'left_brand', 'left_title', 'left_color', 'left_price',\n",
       "       'right_brand', 'right_title', 'right_color', 'right_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65b65566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24345, 9)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4064848",
   "metadata": {},
   "source": [
    "# UNLABELLED set preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec446d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carry out same steps as above for unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b33fe1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_test_df = pd.read_parquet('offers_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad0d543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_test_df['brand'] = offers_test_df['brand'].apply(process_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6778b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_test_df['price'] = offers_test_df['price'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3bb0a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36636, 10)\n",
      "(70105, 10)\n",
      "(36578, 10)\n",
      "(70090, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Split zalando and aboutyou offers into their own dataframes\n",
    "\n",
    "zal_offers = offers_test_df[offers_test_df['shop']=='zalando']\n",
    "aboutyou_offers = offers_test_df[offers_test_df['shop']=='aboutyou']\n",
    "\n",
    "print(zal_offers.shape)\n",
    "print(aboutyou_offers.shape)\n",
    "\n",
    "zal_offers.dropna(inplace=True)\n",
    "aboutyou_offers.dropna(inplace=True)\n",
    "\n",
    "print(zal_offers.shape)\n",
    "print(aboutyou_offers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abfffb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "zal_offers['description'] = zal_offers['description'].apply(process_zal_descr)\n",
    "aboutyou_offers['description'] = aboutyou_offers['description'].apply(process_aboutyou_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41b08581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "zal_offers['color'] = zal_offers['color'].apply(process_zal_color)\n",
    "aboutyou_offers['color'] = aboutyou_offers['color'].apply(process_aboutyou_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71c60c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "zal_offers['title'] = zal_offers['title'].apply(process_zal_title)\n",
    "aboutyou_offers['title'] = aboutyou_offers['title'].apply(process_aboutyou_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c2283ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:65: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "source": [
    "# The equivalent of the above train loop, for the test set\n",
    "\n",
    "import os\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "# Get a list of brands to look at\n",
    "zal_brands = zal_offers['brand'].unique()\n",
    "aboutyou_brands = aboutyou_offers['brand'].unique()\n",
    "brand_list = list(set(zal_brands).intersection(aboutyou_brands))\n",
    "# Removing tom becuase it is causing the notebook to crash\n",
    "brand_list.remove('tom')\n",
    "\n",
    "# only columns of interest for now\n",
    "cols = ['offer_id', 'brand', 'title', 'color', 'description', 'price']\n",
    "\n",
    "for brand in brand_list:\n",
    "    \n",
    "    # Only take columns of interest\n",
    "    temp_zal = zal_offers[zal_offers['brand'] == brand][cols]\n",
    "    temp_aboutyou = aboutyou_offers[aboutyou_offers['brand'] == brand][cols]\n",
    "        \n",
    "    # Format column names as per deepmatcher requirements\n",
    "    temp_zal = temp_zal.add_prefix('left_')\n",
    "    temp_aboutyou = temp_aboutyou.add_prefix('right_')\n",
    "        \n",
    "    # Create an intra-brand cartesian product\n",
    "    brand_cross = temp_zal.merge(temp_aboutyou, how='cross')\n",
    "    \n",
    "    drop_cols = ['left_description', 'right_description']\n",
    "        \n",
    "    # Prune from cartesian product pairs with more than 6 euro in price difference\n",
    "    if not brand_cross.empty:\n",
    "        brand_cross['price_diff'] = brand_cross.apply(price_diff, axis=1)\n",
    "        brand_cross = brand_cross[brand_cross['price_diff'] <= 2.5]\n",
    "        drop_cols.append('price_diff')\n",
    "        \n",
    "    if not brand_cross.empty:\n",
    "        brand_cross['color_compare'] = brand_cross.apply(compare_color, axis=1)\n",
    "        brand_cross = brand_cross[brand_cross['color_compare'] == True]\n",
    "        drop_cols.append('color_compare')\n",
    "            \n",
    "    if not brand_cross.empty:\n",
    "        brand_cross['title_match'] = brand_cross.apply(title_words_in_common, axis=1)\n",
    "        brand_cross = brand_cross[brand_cross['title_match'] == True]\n",
    "        drop_cols.append('title_match')\n",
    "        \n",
    "    # Prune from cartesian product pairs with fewer than six words in common in the description\n",
    "    if not brand_cross.empty:\n",
    "        brand_cross['words_in_common'] = brand_cross.apply(desc_words_in_common, axis=1)\n",
    "        brand_cross = brand_cross[brand_cross['words_in_common'] > 5]\n",
    "        drop_cols.append('words_in_common')\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    brand_cross = brand_cross.drop(drop_cols, 1)\n",
    "    \n",
    "    test_df = test_df.append(brand_cross, ignore_index=True)\n",
    "    \n",
    "test_offer_ids = test_df[['left_offer_id', 'right_offer_id']]\n",
    "test_df = test_df.drop(['left_offer_id', 'right_offer_id'], 1)\n",
    "    \n",
    "# Update index name\n",
    "test_df.index.names = ['id']\n",
    "test_offer_ids.index.names = ['id']\n",
    "    \n",
    "# Save as CSVs\n",
    "cwd = str(os.getcwd())\n",
    "test_df.to_csv(cwd + '/test_set.csv')\n",
    "test_offer_ids.to_csv(cwd + '/test_offer_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f0511ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37541, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6051825d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37541, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_offer_ids.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
