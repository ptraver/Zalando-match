{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3o8SeNvv3nZ",
    "outputId": "0be3605f-fffd-4e94-a534-05808d113255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 50 kB 3.2 MB/s \n",
      "\u001b[K     |████████████████████████████████| 68 kB 5.6 MB/s \n",
      "\u001b[?25h  Building wheel for deepmatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Check for deepmatcher\n",
    "try:\n",
    "    import deepmatcher\n",
    "except:\n",
    "    !pip install -qqq deepmatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jwy5Qul1wSC8"
   },
   "outputs": [],
   "source": [
    "# Import deepmatcher\n",
    "import deepmatcher as dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qiRvlEZEwWEh",
    "outputId": "9666b2db-477e-4d47-84dc-5f805c11cf42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and check pytorch\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkSSkkIZwYYK",
    "outputId": "bc5f632f-e666-4ac7-e711-70d4074024d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-28 07:43:34--  https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.de.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9584991379 (8.9G) [application/zip]\n",
      "Saving to: ‘/root/.vector_cache/wiki.de.zip.1’\n",
      "\n",
      "wiki.de.zip.1       100%[===================>]   8.93G  42.7MB/s    in 3m 24s  \n",
      "\n",
      "2022-03-28 07:46:59 (44.8 MB/s) - ‘/root/.vector_cache/wiki.de.zip.1’ saved [9584991379/9584991379]\n",
      "\n",
      "Archive:  /root/.vector_cache/wiki.de.zip\n",
      "  inflating: /root/.vector_cache/wiki.de.vec  \n",
      "replace /root/.vector_cache/wiki.de.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
      "  inflating: /root/.vector_cache/wiki.de.bin  \n"
     ]
    }
   ],
   "source": [
    "# Download fastText German language model\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.de.zip --directory-prefix=/root/.vector_cache\n",
    "!unzip /root/.vector_cache/wiki.de.zip -d /root/.vector_cache/\n",
    "!rm /root/.vector_cache/wiki.de.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7FRdEa4zwe_7",
    "outputId": "7a63ca6c-2916-4429-b216-00412edd67d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:deepmatcher.data.dataset:Rebuilding data cache because: ['Data file list has changed.', 'One or more data files have been modified.']\n",
      "\n",
      "Reading and processing data from \"sample_data/zalando/train_1.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"sample_data/zalando/validation_1.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"sample_data/zalando/test_1.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Building vocabulary\n",
      "0% [####] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "\n",
      "Computing principal components\n",
      "0% [####] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1000: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 9210006\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:990: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2748: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:  109.8 | Load Time:    0.6 || F1:  33.16 | Prec:  20.60 | Rec:  85.02 || Ex/s:  30.14\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   12.8 | Load Time:    0.2 || F1:  36.79 | Prec:  22.70 | Rec:  97.02 || Ex/s:  86.50\n",
      "\n",
      "* Best F1: tensor(36.7946)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:  109.2 | Load Time:    0.6 || F1:  46.41 | Prec:  31.91 | Rec:  85.02 || Ex/s:  30.30\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   12.6 | Load Time:    0.2 || F1:  46.72 | Prec:  31.42 | Rec:  91.07 || Ex/s:  88.10\n",
      "\n",
      "* Best F1: tensor(46.7176)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:  110.5 | Load Time:    0.6 || F1:  52.90 | Prec:  37.37 | Rec:  90.49 || Ex/s:  29.94\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   13.1 | Load Time:    0.2 || F1:  49.83 | Prec:  35.22 | Rec:  85.12 || Ex/s:  85.12\n",
      "\n",
      "* Best F1: tensor(49.8258)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:  108.5 | Load Time:    0.6 || F1:  58.18 | Prec:  42.43 | Rec:  92.51 || Ex/s:  30.49\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   12.8 | Load Time:    0.2 || F1:  50.76 | Prec:  37.22 | Rec:  79.76 || Ex/s:  86.73\n",
      "\n",
      "* Best F1: tensor(50.7576)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  110.3 | Load Time:    0.6 || F1:  63.05 | Prec:  47.40 | Rec:  94.13 || Ex/s:  30.00\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   12.8 | Load Time:    0.2 || F1:  49.51 | Prec:  36.81 | Rec:  75.60 || Ex/s:  86.92\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:  108.3 | Load Time:    0.6 || F1:  67.00 | Prec:  51.53 | Rec:  95.75 || Ex/s:  30.53\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   12.6 | Load Time:    0.2 || F1:  50.62 | Prec:  38.85 | Rec:  72.62 || Ex/s:  88.36\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  111.4 | Load Time:    0.6 || F1:  70.18 | Prec:  54.92 | Rec:  97.17 || Ex/s:  29.71\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   13.1 | Load Time:    0.2 || F1:  48.85 | Prec:  36.08 | Rec:  75.60 || Ex/s:  85.03\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  110.3 | Load Time:    0.6 || F1:  73.46 | Prec:  58.83 | Rec:  97.77 || Ex/s:  30.01\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   12.5 | Load Time:    0.2 || F1:  51.12 | Prec:  38.77 | Rec:  75.00 || Ex/s:  88.65\n",
      "\n",
      "* Best F1: tensor(51.1156)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:  111.1 | Load Time:    0.6 || F1:  76.66 | Prec:  62.79 | Rec:  98.38 || Ex/s:  29.78\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   12.7 | Load Time:    0.2 || F1:  51.50 | Prec:  40.27 | Rec:  71.43 || Ex/s:  87.47\n",
      "\n",
      "* Best F1: tensor(51.5021)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  110.4 | Load Time:    0.6 || F1:  80.59 | Prec:  67.87 | Rec:  99.19 || Ex/s:  29.97\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   12.6 | Load Time:    0.2 || F1:  51.96 | Prec:  39.75 | Rec:  75.00 || Ex/s:  88.51\n",
      "\n",
      "* Best F1: tensor(51.9588)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_c7e52e98-7319-4ed7-870c-0edb32dee154\", \"model_1.pth\", 117402437)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:deepmatcher.data.dataset:Rebuilding data cache because: ['Data file list has changed.', 'One or more data files have been modified.']\n",
      "\n",
      "Reading and processing data from \"sample_data/zalando/train_2.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"sample_data/zalando/validation_2.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"sample_data/zalando/test_2.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Building vocabulary\n",
      "0% [#######] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "\n",
      "Computing principal components\n",
      "0% [#######] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1000: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 9210006\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:990: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2748: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:  216.7 | Load Time:    1.2 || F1:  23.33 | Prec:  13.32 | Rec:  93.75 || Ex/s:  31.19\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   24.9 | Load Time:    0.4 || F1:  33.01 | Prec:  20.26 | Rec:  89.01 || Ex/s:  91.03\n",
      "\n",
      "* Best F1: tensor(33.0097)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:  229.4 | Load Time:    1.2 || F1:  35.76 | Prec:  22.02 | Rec:  95.18 || Ex/s:  29.48\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   25.1 | Load Time:    0.4 || F1:  37.29 | Prec:  23.78 | Rec:  86.39 || Ex/s:  90.32\n",
      "\n",
      "* Best F1: tensor(37.2881)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:  247.5 | Load Time:    1.2 || F1:  42.38 | Prec:  27.13 | Rec:  96.79 || Ex/s:  27.33\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   25.5 | Load Time:    0.5 || F1:  41.42 | Prec:  27.62 | Rec:  82.72 || Ex/s:  88.92\n",
      "\n",
      "* Best F1: tensor(41.4155)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:  229.0 | Load Time:    1.2 || F1:  48.18 | Prec:  32.05 | Rec:  96.96 || Ex/s:  29.53\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   24.5 | Load Time:    0.4 || F1:  43.58 | Prec:  30.48 | Rec:  76.44 || Ex/s:  92.65\n",
      "\n",
      "* Best F1: tensor(43.5821)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  245.3 | Load Time:    1.2 || F1:  53.04 | Prec:  36.42 | Rec:  97.50 || Ex/s:  27.58\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   25.6 | Load Time:    0.5 || F1:  44.71 | Prec:  33.16 | Rec:  68.59 || Ex/s:  88.56\n",
      "\n",
      "* Best F1: tensor(44.7099)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:  263.9 | Load Time:    1.2 || F1:  57.16 | Prec:  40.28 | Rec:  98.39 || Ex/s:  25.64\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   25.3 | Load Time:    0.4 || F1:  45.33 | Prec:  33.85 | Rec:  68.59 || Ex/s:  89.59\n",
      "\n",
      "* Best F1: tensor(45.3287)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  269.1 | Load Time:    1.2 || F1:  60.32 | Prec:  43.38 | Rec:  98.93 || Ex/s:  25.14\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   25.1 | Load Time:    0.5 || F1:  45.71 | Prec:  34.69 | Rec:  67.02 || Ex/s:  90.36\n",
      "\n",
      "* Best F1: tensor(45.7143)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  293.9 | Load Time:    1.2 || F1:  63.07 | Prec:  46.25 | Rec:  99.11 || Ex/s:  23.03\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   24.8 | Load Time:    0.4 || F1:  43.08 | Prec:  34.04 | Rec:  58.64 || Ex/s:  91.65\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:  301.6 | Load Time:    1.2 || F1:  66.55 | Prec:  50.00 | Rec:  99.46 || Ex/s:  22.45\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   24.9 | Load Time:    0.5 || F1:  42.94 | Prec:  34.05 | Rec:  58.12 || Ex/s:  91.10\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  302.9 | Load Time:    1.2 || F1:  69.62 | Prec:  53.56 | Rec:  99.46 || Ex/s:  22.36\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [█████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   24.8 | Load Time:    0.5 || F1:  43.78 | Prec:  35.50 | Rec:  57.07 || Ex/s:  91.56\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_0c219404-df06-4b1e-a2f5-7db2f923e6f0\", \"model_2.pth\", 117462213)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:deepmatcher.data.dataset:Rebuilding data cache because: ['Data file list has changed.', 'One or more data files have been modified.']\n",
      "\n",
      "Reading and processing data from \"sample_data/zalando/train_3.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"sample_data/zalando/validation_3.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"sample_data/zalando/test_3.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Building vocabulary\n",
      "0% [################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "\n",
      "Computing principal components\n",
      "0% [################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1000: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 9210006\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:990: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2748: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:  539.2 | Load Time:    2.8 || F1:  13.57 | Prec:   7.29 | Rec:  96.78 || Ex/s:  29.64\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   55.3 | Load Time:    0.9 || F1:  14.61 | Prec:   7.89 | Rec:  99.08 || Ex/s:  97.16\n",
      "\n",
      "* Best F1: tensor(14.6078)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:  559.4 | Load Time:    2.7 || F1:  16.70 | Prec:   9.14 | Rec:  96.99 || Ex/s:  28.58\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   55.7 | Load Time:    1.0 || F1:  17.78 | Prec:   9.78 | Rec:  97.25 || Ex/s:  96.31\n",
      "\n",
      "* Best F1: tensor(17.7803)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:08:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:  506.2 | Load Time:    2.9 || F1:  19.22 | Prec:  10.66 | Rec:  97.92 || Ex/s:  31.56\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   57.7 | Load Time:    1.0 || F1:  18.33 | Prec:  10.13 | Rec:  96.64 || Ex/s:  93.13\n",
      "\n",
      "* Best F1: tensor(18.3348)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:08:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:  503.1 | Load Time:    2.8 || F1:  21.09 | Prec:  11.81 | Rec:  98.23 || Ex/s:  31.76\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   57.1 | Load Time:    1.0 || F1:  19.06 | Prec:  10.57 | Rec:  96.64 || Ex/s:  94.01\n",
      "\n",
      "* Best F1: tensor(19.0591)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:08:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  500.8 | Load Time:    2.8 || F1:  23.96 | Prec:  13.64 | Rec:  98.65 || Ex/s:  31.90\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   56.0 | Load Time:    1.0 || F1:  19.87 | Prec:  11.13 | Rec:  92.66 || Ex/s:  95.82\n",
      "\n",
      "* Best F1: tensor(19.8689)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:08:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:  500.7 | Load Time:    2.8 || F1:  26.53 | Prec:  15.32 | Rec:  98.75 || Ex/s:  31.91\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   57.6 | Load Time:    1.0 || F1:  20.60 | Prec:  11.64 | Rec:  89.60 || Ex/s:  93.25\n",
      "\n",
      "* Best F1: tensor(20.5975)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:08:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  499.5 | Load Time:    2.8 || F1:  28.67 | Prec:  16.76 | Rec:  99.17 || Ex/s:  31.99\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   55.6 | Load Time:    0.9 || F1:  20.03 | Prec:  11.25 | Rec:  90.83 || Ex/s:  96.69\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:08:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  500.4 | Load Time:    2.8 || F1:  31.48 | Prec:  18.69 | Rec:  99.69 || Ex/s:  31.93\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   55.2 | Load Time:    0.9 || F1:  22.51 | Prec:  12.90 | Rec:  88.07 || Ex/s:  97.28\n",
      "\n",
      "* Best F1: tensor(22.5088)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:08:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:  502.8 | Load Time:    2.8 || F1:  33.98 | Prec:  20.48 | Rec:  99.69 || Ex/s:  31.77\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   55.0 | Load Time:    0.9 || F1:  23.36 | Prec:  13.63 | Rec:  81.65 || Ex/s:  97.62\n",
      "\n",
      "* Best F1: tensor(23.3596)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:08:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  497.2 | Load Time:    2.7 || F1:  36.26 | Prec:  22.14 | Rec: 100.00 || Ex/s:  32.14\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   57.1 | Load Time:    1.0 || F1:  24.15 | Prec:  14.27 | Rec:  78.59 || Ex/s:  94.12\n",
      "\n",
      "* Best F1: tensor(24.1541)\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_c1803758-f494-4b3e-b4f6-8b7583b121a6\", \"model_3.pth\", 118877445)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop to train Msmall, Mmedium and Mlarge on the appropriate dataset\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "import time\n",
    "\n",
    "#List required for pos_neg_ration hyperparameter in training\n",
    "pos_negs = [0,6,12,16]\n",
    "\n",
    "for i in range(1,4):\n",
    "  #data setup\n",
    "  train, validation, test = dm.data.process(\n",
    "    path='sample_data/zalando',\n",
    "    train=f'train_{i}.csv',\n",
    "    validation=f'validation_{i}.csv',\n",
    "    test=f'test_{i}.csv',\n",
    "    embeddings='fasttext.de.bin')\n",
    "  \n",
    "  #define model\n",
    "  model = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "\n",
    "  #train model\n",
    "  model.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    best_save_path='hybrid_model.pth',\n",
    "    pos_neg_ratio=pos_negs[i])\n",
    "  \n",
    "  #save model\n",
    "  model.save_state(f'sample_data/zalando/model_{i}.pth')\n",
    "\n",
    "  time.sleep(60)\n",
    "\n",
    "  #download model\n",
    "  files.download(f'sample_data/zalando/model_{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jIlR-Li-lcSE",
    "outputId": "1603ec82-f264-42b4-ee49-6814f0027db6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1000: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "\n",
      "Reading and processing data from \"sample_data/zalando/test_set.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:990: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  277.6 | Load Time:    5.6 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading and processing data from \"sample_data/zalando/test_set.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  281.8 | Load Time:    5.7 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading and processing data from \"sample_data/zalando/test_set.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  278.7 | Load Time:    5.5 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for each model on test set and save as csvs\n",
    "\n",
    "for i in range(1, 4):\n",
    "  model = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "  model.load_state(f'sample_data/zalando/model_{i}.pth')\n",
    "\n",
    "  unlabeled = dm.data.process_unlabeled(\n",
    "    path='sample_data/zalando/test_set.csv',\n",
    "    trained_model=model)\n",
    "\n",
    "  test_predictions = model.run_prediction(unlabeled)\n",
    "  test_predictions.to_csv(f'test_predictions_m{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vqj4YZ8t4N2i"
   },
   "outputs": [],
   "source": [
    "# Define ensemble voting policy\n",
    "def unanimous_ensemble(x):\n",
    "  return x['m1'] > 0.5 and x['m2'] > 0.5 and x['m3'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQiXdfQr3Ris"
   },
   "outputs": [],
   "source": [
    "# Load test set predictions to dataframes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "m1 = pd.read_csv('test_predictions_m1.csv')\n",
    "m2_preds = pd.read_csv('test_predictions_m2.csv')\n",
    "m3_preds = pd.read_csv('test_predictions_m3.csv')\n",
    "test_offer_ids = pd.read_csv('sample_data/zalando/test_offer_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srd0IM7m9qgp",
    "outputId": "92a49dd4-1354-47df-db83-b397375ba632"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37541, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_offer_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQgH8cKL33XC",
    "outputId": "db99f174-c245-45e5-ed67-cbca1b5f2914"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe full_preds giving the results of unanimous ensemble voting\n",
    "\n",
    "full_preds = m1.join(m2_preds, lsuffix='_m1', rsuffix='_m2')\n",
    "full_preds = full_preds.join(m3_preds)\n",
    "full_preds = full_preds.drop(['id_m1', 'id_m2', 'id'], 1)\n",
    "full_preds.columns = ['m1', 'm2', 'm3']\n",
    "full_preds.head()\n",
    "full_preds['match'] = full_preds.apply(unanimous_ensemble, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOIkxr9t9wUr",
    "outputId": "9d7afc2e-6c4b-408b-f453-8c9db0ba4f9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe matches_test_predicted to give the output in the correct format\n",
    "\n",
    "matches_test_predicted = test_offer_ids[full_preds['match'] == True]\n",
    "matches_test_predicted = matches_test_predicted.drop(['id'], 1)\n",
    "idx = [i for i in range(len(matches_test_predicted))]\n",
    "matches_test_predicted.index = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H8TIJElUWZ1I"
   },
   "outputs": [],
   "source": [
    "matches_test_predicted.columns = ['zalando', 'aboutyou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR-4HPbX39vD",
    "outputId": "0819fa69-1564-44c5-a7ea-9521300a4a2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6519, 2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_test_predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "Y9vqOTRp9ffv",
    "outputId": "4da7b1f5-b7b3-4ee3-8caf-939eb15e7a42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1e1728ae-ee0e-4705-882a-524ba54862ba\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zalando</th>\n",
       "      <th>aboutyou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d0d991-4264-4dce-9980-17bde9d7b984</td>\n",
       "      <td>ac11d986-bb9e-471d-a8cb-0098e8b790a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228</td>\n",
       "      <td>f256b584-a6e1-425c-918f-216ea885deda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228</td>\n",
       "      <td>669ecbf7-9eb1-4a3e-83ab-3d7c1666848c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228</td>\n",
       "      <td>dec5bfdd-0c4c-4c0c-973e-cc954c239ae0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228</td>\n",
       "      <td>cb02b94e-d27e-4590-afac-f17648d9bd28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228</td>\n",
       "      <td>45eee7cb-5e00-4f35-ab23-4d5e07d9624a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228</td>\n",
       "      <td>2e4848e4-95eb-43e1-9026-b5b3a2051e93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228</td>\n",
       "      <td>ac11d986-bb9e-471d-a8cb-0098e8b790a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fbafcb97-a2ce-4137-8441-cda9560a311d</td>\n",
       "      <td>80fbb088-1669-4143-9b94-d0c1c9f358ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fbafcb97-a2ce-4137-8441-cda9560a311d</td>\n",
       "      <td>34ab0d50-37de-4433-ba73-2c5a378c9458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1a8a1b88-5ff8-4208-a6d4-8bc59789bc47</td>\n",
       "      <td>a535ae7a-0cb6-4cb9-8a5e-98d9fc9fd693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1a8a1b88-5ff8-4208-a6d4-8bc59789bc47</td>\n",
       "      <td>612a5992-b7e4-4c2c-a727-650d28acdf47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ce65601a-048b-44c0-9107-a11da1425f97</td>\n",
       "      <td>a003ecfc-b9a1-4ce5-8aca-2d13fd673c28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ce65601a-048b-44c0-9107-a11da1425f97</td>\n",
       "      <td>72e0bafb-6f24-4d9e-b58d-a78a6b8e1638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fe4589b3-c151-4d83-a17f-3364d6ada6bc</td>\n",
       "      <td>230efb92-ca60-418e-90d3-bac15ad35141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>be4da324-6ec8-420c-95f6-6d8d24337826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>c3c3d1da-6aad-4e2a-b41f-bdd595f7bc8e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>8e15a4ef-e7b3-4217-8838-dc4aa43d289e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>2eb05cb9-4e43-4eed-a578-cc83d8accd05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>8c1f2c85-3b20-453f-8d74-f3a818270aa2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>31991b2d-4936-4fd7-b3a3-b98c1c77a774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>379e446d-4e02-45d6-94a0-46ed148253d6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>153332ce-ea72-4f84-827a-28f6163890fb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>75e8eecf-628e-42cc-b2bd-eb99d22d7e89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ffc4c017-9597-4bf1-af5c-acb698d24fa0</td>\n",
       "      <td>facf13ce-70f4-4bc7-a19c-47f81fd0154b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e1728ae-ee0e-4705-882a-524ba54862ba')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1e1728ae-ee0e-4705-882a-524ba54862ba button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1e1728ae-ee0e-4705-882a-524ba54862ba');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                 zalando                              aboutyou\n",
       "0   37d0d991-4264-4dce-9980-17bde9d7b984  ac11d986-bb9e-471d-a8cb-0098e8b790a5\n",
       "1   bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228  f256b584-a6e1-425c-918f-216ea885deda\n",
       "2   bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228  669ecbf7-9eb1-4a3e-83ab-3d7c1666848c\n",
       "3   bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228  dec5bfdd-0c4c-4c0c-973e-cc954c239ae0\n",
       "4   bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228  cb02b94e-d27e-4590-afac-f17648d9bd28\n",
       "5   bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228  45eee7cb-5e00-4f35-ab23-4d5e07d9624a\n",
       "6   bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228  2e4848e4-95eb-43e1-9026-b5b3a2051e93\n",
       "7   bf02a3e7-3c12-4ae1-80e3-e2dff7f9f228  ac11d986-bb9e-471d-a8cb-0098e8b790a5\n",
       "8   fbafcb97-a2ce-4137-8441-cda9560a311d  80fbb088-1669-4143-9b94-d0c1c9f358ae\n",
       "9   fbafcb97-a2ce-4137-8441-cda9560a311d  34ab0d50-37de-4433-ba73-2c5a378c9458\n",
       "10  1a8a1b88-5ff8-4208-a6d4-8bc59789bc47  a535ae7a-0cb6-4cb9-8a5e-98d9fc9fd693\n",
       "11  1a8a1b88-5ff8-4208-a6d4-8bc59789bc47  612a5992-b7e4-4c2c-a727-650d28acdf47\n",
       "12  ce65601a-048b-44c0-9107-a11da1425f97  a003ecfc-b9a1-4ce5-8aca-2d13fd673c28\n",
       "13  ce65601a-048b-44c0-9107-a11da1425f97  72e0bafb-6f24-4d9e-b58d-a78a6b8e1638\n",
       "14  fe4589b3-c151-4d83-a17f-3364d6ada6bc  230efb92-ca60-418e-90d3-bac15ad35141\n",
       "15  ffc4c017-9597-4bf1-af5c-acb698d24fa0  be4da324-6ec8-420c-95f6-6d8d24337826\n",
       "16  ffc4c017-9597-4bf1-af5c-acb698d24fa0  c3c3d1da-6aad-4e2a-b41f-bdd595f7bc8e\n",
       "17  ffc4c017-9597-4bf1-af5c-acb698d24fa0  8e15a4ef-e7b3-4217-8838-dc4aa43d289e\n",
       "18  ffc4c017-9597-4bf1-af5c-acb698d24fa0  2eb05cb9-4e43-4eed-a578-cc83d8accd05\n",
       "19  ffc4c017-9597-4bf1-af5c-acb698d24fa0  8c1f2c85-3b20-453f-8d74-f3a818270aa2\n",
       "20  ffc4c017-9597-4bf1-af5c-acb698d24fa0  31991b2d-4936-4fd7-b3a3-b98c1c77a774\n",
       "21  ffc4c017-9597-4bf1-af5c-acb698d24fa0  379e446d-4e02-45d6-94a0-46ed148253d6\n",
       "22  ffc4c017-9597-4bf1-af5c-acb698d24fa0  153332ce-ea72-4f84-827a-28f6163890fb\n",
       "23  ffc4c017-9597-4bf1-af5c-acb698d24fa0  75e8eecf-628e-42cc-b2bd-eb99d22d7e89\n",
       "24  ffc4c017-9597-4bf1-af5c-acb698d24fa0  facf13ce-70f4-4bc7-a19c-47f81fd0154b"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_test_predicted.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VW6e9GAVS-xK"
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "matches_test_predicted.to_parquet('matches_test_predicted.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "cV5FTE_oW4NV",
    "outputId": "e8634c34-278b-4be6-e0ad-a4218359e756"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_8d3af7ac-2eeb-460c-884e-8fb51ec2b978\", \"matches_test_predicted.parquet\", 269119)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download('matches_test_predicted.parquet')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deepmatcher3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
